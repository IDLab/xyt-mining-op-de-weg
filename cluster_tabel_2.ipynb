{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory DB Scan\n",
    "\n",
    "## Articles\n",
    "https://www.sciencedirect.com/science/article/pii/S0957417417307698\n",
    "https://www.sciencedirect.com/science/article/pii/S2352146518301820\n",
    "https://www.sciencedirect.com/science/article/pii/S1877050915008741\n",
    "https://github.com/turi-code/userguide/blob/master/clustering/dbscan.md\n",
    "\n",
    "## Summary theory\n",
    "4 method for clustering:\n",
    "    1. partitioning approaches (where the number of clusters is pre-assigned)\n",
    "    2. grid-based (where the object space is divided into a pre-assigned number of cells)\n",
    "    3. hierarchical (where the data is organized in multiple levels) \n",
    "    4. density-based (where density notion is considered).\n",
    "\n",
    "DBScan is density-based. It needs two parameters:\n",
    "    1. Radius of a circle around the data point\n",
    "    2. Minimum number of points that should be in the circle\n",
    "    \n",
    "DBSCAN-TE is used to group GPS points into clusters (stopping points) and\n",
    "noise (moving points) due to their difference in spatial density, temporal \n",
    "sequence, and entropy index. Activity stops are then refined from stopping \n",
    "points by SVMs. The structure of the two-step methodology is shown in Fig. 1.\n",
    "\n",
    "## Install packages\n",
    "    1. link voor download packages https://www.lfd.uci.edu/~gohlke/pythonlibs/\n",
    "    2. installeer: geopandas, GDAL, Fiona, Basemap, Shapely, Pyproj, wheel \n",
    "    3. Bestand van download naar script map anaconda \n",
    "    4. pip install bestand.whl (behalve bij geopandas, deze moet je installeren via GitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import great_circle\n",
    "from shapely.geometry import MultiPoint\n",
    "from sklearn import preprocessing\n",
    "# import plotly.plotly as py \n",
    "# import plotly\n",
    "# plotly.tools.set_credentials_file(username='candy_93j', api_key='pdU9f5lyr1CoSmwpj2r6')\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "# from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.io import push_notebook, show, output_notebook, curdoc, show\n",
    "from bokeh.models import ColumnDataSource, Plot, LinearAxis, Grid\n",
    "from bokeh.models.glyphs import VBar\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inladen csv (uitkomst vorige script)\n",
    "df = pd.read_csv('XYT_speed_distance.csv')\n",
    "df = df[:-1] #Laatste regel is NAN\n",
    "df_old = df #Nodig voor merge verderop in script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schaal lat, lon en speed voor dbscan\n",
    "coords_speed = np.asarray(df[['Lat_a', 'Lon_a', \"speed_kmu\"]])\n",
    "coords = preprocessing.scale(coords_speed)\n",
    "# coords = np.asarray(df[['Lat_a', 'Lon_a']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##bereken EPS door K-distance elbow (Nu niet van toepassing)\n",
    "# def k_distances2(x, k):\n",
    "#     dim0 = x.shape[0]\n",
    "#     dim1 = x.shape[1]\n",
    "#     p=-2*x.dot(x.T)+np.sum(x**2, axis=1).T+ np.repeat(np.sum(x**2, axis=1),dim0,axis=0).reshape(dim0,dim0)\n",
    "#     p = np.sqrt(p)\n",
    "#     p.sort(axis=1)\n",
    "#     p=p[:,:k]\n",
    "#     pm= p.flatten()\n",
    "#     pm= np.sort(pm)\n",
    "#     return p, pm\n",
    "# m, m2= k_distances2(coords, 5)\n",
    "# plt.plot(m2)\n",
    "# plt.ylabel(\"k-distances\")\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Berekenen de clusters met DBSCAN\n",
    "# # kms_per_radian = 6371.0088\n",
    "# m_per_radian = 6371008.8\n",
    "# # epsilon = 0.005 / kms_per_radian\n",
    "# epsilon_m = 0.005 / m_per_radian #5 meter kwam uit k_distance\n",
    "epsilon = 0.154152\n",
    "min_samples = 3\n",
    "db = DBSCAN(eps=epsilon, min_samples=min_samples, algorithm='ball_tree').fit(coords)\n",
    "cluster_labels = db.labels_\n",
    "num_clusters = len(set(cluster_labels))\n",
    "print('Number of clusters: {}'.format(num_clusters))\n",
    "\n",
    "#Clusterlabels naar column\n",
    "df[\"cluster\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##visualize clusters (Nu niet relevant)\n",
    "# core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "# core_samples_mask[db.core_sample_indices_] = True\n",
    "# n_clusters_1 = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "\n",
    "# unique_labels = set(cluster_labels)\n",
    "# colors = [plt.cm.Spectral(each)\n",
    "#           for each in np.linspace(0, 1, len(unique_labels))]\n",
    "# for k, col in zip(unique_labels, colors):\n",
    "#     if k == -1:\n",
    "#         # Black used for noise.\n",
    "#         col = [0, 0, 0, 1]\n",
    "\n",
    "#     class_member_mask = (cluster_labels == k)\n",
    "\n",
    "#     xy = coords[class_member_mask & core_samples_mask]\n",
    "#     plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "#              markeredgecolor='k', markersize=14)\n",
    "\n",
    "#     xy = coords[class_member_mask & ~core_samples_mask]\n",
    "#     plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "#              markeredgecolor='k', markersize=6)\n",
    "\n",
    "# plt.title('Estimated number of clusters: %d' % n_clusters_1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge met de oude gegevens \n",
    "df = df[[\"VgNr\", \"cluster\"]]\n",
    "df_new = pd.merge(df_old, df, on=\"VgNr\", how=\"left\")\n",
    "\n",
    "df_new.to_csv(\"total_eps015_MinSamples3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clusters naar middelste XY\n",
    "coords_new = np.asarray(df_new[['Lat_a', 'Lon_a', \"speed_kmu\"]])\n",
    "clusters = pd.Series([coords_new[cluster_labels == n] for n in range(num_clusters)])\n",
    "clusters = clusters[:-1]\n",
    "\n",
    "def get_centermost_point(cluster):\n",
    "    centroid = (MultiPoint(cluster).centroid.x, MultiPoint(cluster).centroid.y)\n",
    "    centermost_point = min(cluster, key=lambda point: great_circle(point, centroid).m)\n",
    "    return tuple(centermost_point)\n",
    "centermost_points = clusters.map(get_centermost_point)\n",
    "\n",
    "lats, lons, speed = zip(*centermost_points)\n",
    "rep_points = pd.DataFrame({'Lon_a':lons, 'Lat_a':lats, 'speed_kmu':speed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create cluster table \n",
    "kmu_per_cluster = df_new.groupby('cluster_x')['speed_kmu'].mean().reset_index(name='kmu_per_cluster')\n",
    "NoP_per_cluster = df_new.groupby('cluster_x')[\"cluster_x\"].count().reset_index(name='NoP_per_cluster')\n",
    "NoP_kmu_per_cluster = pd.merge(kmu_per_cluster, NoP_per_cluster, on=[\"cluster_x\"], how=\"left\")\n",
    "ID_centerpoint = df_new[[\"VgNr\", \"Lat_a\", \"Lon_a\", \"cluster_x\"]]\n",
    "ID_centerpoint = pd.merge(rep_points, ID_centerpoint, on=[\"Lon_a\", \"Lat_a\"], how=\"left\")\n",
    "cluster_table = pd.merge(ID_centerpoint, NoP_kmu_per_cluster, on=[\"cluster_x\"], how=\"left\")\n",
    "ct = cluster_table[cluster_table[\"kmu_per_cluster\"] <=10]\n",
    "ct.head(100)\n",
    "\n",
    "ct.to_csv(\"ClusterTable_eps015_MinSamples_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Visualisatie 1: clusters lan - lon\n",
    "\n",
    "# output to static HTML file\n",
    "output_file(\"line.html\")\n",
    "\n",
    "p = figure(plot_width=500, plot_height=500)\n",
    "\n",
    "# add a circle renderer with a size, color, and alpha\n",
    "p.circle(x=ct[\"Lat_a\"], y=ct[\"Lon_a\"], size=20, color=\"navy\", alpha=0.5)\n",
    "\n",
    "# show the results\n",
    "show(p)\n",
    "# import plotly.offline as offline\n",
    "\n",
    "# # Create a trace\n",
    "# trace = go.Scatter(\n",
    "#     x = ct[\"Lon_a\"],\n",
    "#     y = ct[\"Lat_a\"],\n",
    "#     mode = \"markers\"\n",
    "# )\n",
    "\n",
    "# data = [trace]\n",
    "\n",
    "# # Plot and embed in ipython notebook!\n",
    "# iplot(data)\n",
    "\n",
    "\n",
    "# # x = ct[\"Lon_a\"]\n",
    "# # y = ct[\"Lat_a\"]\n",
    "# # # offline.iplot([go.Histogram2dContour(x=x, y=y, contours=dict(coloring='heatmap')),\n",
    "# #        go.Scatter(x=x, y=y, mode='markers', marker=dict(color='white', size=3, opacity=0.3))], show_link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisatie 2: aantal punten per cluster\n",
    "x = ct[\"cluster_x\"]\n",
    "y = ct[\"NoP_per_cluster\"]\n",
    "\n",
    "plot = figure(plot_width=500, plot_height=500)\n",
    "source = ColumnDataSource(dict(x=x,top=y,))\n",
    "\n",
    "glyph = VBar(x=\"x\", top=\"top\", bottom=0, width=0.5, fill_color=\"#b3de69\")\n",
    "plot.add_glyph(source, glyph)\n",
    "\n",
    "show(plot)\n",
    "\n",
    "\n",
    "# trace = go.Bar(\n",
    "#     x = ct[\"cluster_x\"],\n",
    "#     y = ct[\"NoP_per_cluster\"]\n",
    "# )\n",
    "\n",
    "# data = [trace]\n",
    "# iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisatie 3: gemiddelde snelheid per cluster\n",
    "\n",
    "x = ct[\"cluster_x\"]\n",
    "y = ct[\"kmu_per_cluster\"]\n",
    "\n",
    "plot = figure(plot_width=500, plot_height=500)\n",
    "source = ColumnDataSource(dict(x=x,top=y,))\n",
    "\n",
    "glyph = VBar(x=\"x\", top=\"top\", bottom=0, width=0.5, fill_color=\"#b3de69\")\n",
    "plot.add_glyph(source, glyph)\n",
    "\n",
    "show(plot)\n",
    "\n",
    "# trace = go.Bar(\n",
    "#     x = ct[\"cluster_x\"],\n",
    "#     y = ct[\"kmu_per_cluster\"]\n",
    "# )\n",
    "\n",
    "# data = [trace]\n",
    "# py.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisatie 1: clusters lan - lon\n",
    "\n",
    "# output to static HTML file\n",
    "output_file(\"line.html\")\n",
    "\n",
    "p = figure(plot_width=500, plot_height=500)\n",
    "p.circle(x=ct[\"kmu_per_cluster\"], y=ct[\"NoP_per_cluster\"], size=20, color=\"navy\", alpha=0.5)\n",
    "show(p)\n",
    "\n",
    "# Create a trace\n",
    "# trace = go.Scatter(\n",
    "#     x = ct[\"kmu_per_cluster\"],\n",
    "#     y = ct[\"NoP_per_cluster\"],\n",
    "#     mode = \"markers\"\n",
    "# )\n",
    "\n",
    "# data = [trace]\n",
    "\n",
    "# # Plot and embed in ipython notebook!\n",
    "# py.iplot(data, filename='basic-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.to_csv(\"test_stoplocaties_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor/\n",
    "\n",
    "# X = ct[\"cluster_x\"]\n",
    "# y = ct[\"kmu_per_cluster\"]\n",
    "\n",
    "# for eps in np.arange(0, 1, 0.001):\n",
    "#     model = db = DBSCAN(eps=epsilon, min_samples=1, algorithm='ball_tree').fit(np.radians(coords))\n",
    "#     model.fit(X_train, y_train)\n",
    "#     score = model.score(X_test, y_test)        \n",
    "#     if score > best_score:\n",
    "#         best_score = score\n",
    "#         best_C = C\n",
    "#         best_gamma = gamma \n",
    "# print('Highest Accuracy Score: ', best_score)   \n",
    "\n",
    "# Randomized Search for Algorithm Tuning\n",
    "# import numpy as np\n",
    "# from scipy.stats import uniform as sp_rand\n",
    "# from sklearn import datasets\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# # prepare a range of alpha values to test\n",
    "# alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "# # create and fit a ridge regression model, testing each alpha\n",
    "# model = Ridge()\n",
    "# grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "# grid.fit(dataset., dataset.target)\n",
    "# print(grid)\n",
    "# # summarize the results of the grid search\n",
    "# print(grid.best_score_)\n",
    "# print(grid.best_estimator_.alpha)\n",
    "\n",
    "#  itr = 0, eps = 900, minpts = 5, _step = 100\n",
    "#  while number of outliers < 10  and itr < 10:\n",
    "#       eps = eps + _step\n",
    "#       itr = itr + 1\n",
    "#       dbscan(eps,minpts)\n",
    "\n",
    "# for epsilon in np.array([1, 0.01, 0.001, 0.0001, 0]):\n",
    "#     model =DBSCAN(eps=epsilon, min_samples=1, algorithm='ball_tree').fit(np.radians(coords))\n",
    "\n",
    "\n",
    "# x = np.arange(6).reshape(2,3)\n",
    "\n",
    "# for x in model:\n",
    "#     model = DBSCAN(eps=1, min_samples=1, algorithm='ball_tree').fit(np.radians(coords))\n",
    "\n",
    "#     print(x)\n",
    "# model = DBSCAN(eps=1, min_samples=1, algorithm='ball_tree').fit(np.radians(coords))\n",
    "# for eps in DBSCAN(model):\n",
    "#     print (x)\n",
    "\n",
    "# for x in np.array([1,0.1,0.01,0.001,0.0001,0]):\n",
    "#     print(x)\n",
    "\n",
    "# df_loop = df_new\n",
    "# epsilon_2 = 0.001\n",
    "# coords_speed_2 = np.asarray(df_loop[['Lat_a', 'Lon_a', \"speed_kmu\"]])\n",
    "# coords_2 = preprocessing.scale(coords_speed_2)\n",
    "\n",
    "# def gemiddelde_kmu_per_eps(mean_kmu):\n",
    "#     model = DBSCAN(eps=epsilon_2, min_samples=1, algorithm='ball_tree').fit(np.radians(coords_2))\n",
    "#     cluster_labels_2 = db.labels_\n",
    "#     num_clusters_2 = len(set(cluster_labels_2))\n",
    "#     print('Number of clusters: {}'.format(num_clusters_2))\n",
    "#     df_loop[\"cluster_2\"] = cluster_labels_2\n",
    "#     kmu_per_cluster_2 = df_loop.groupby('cluster_2')['speed_kmu'].mean().reset_index(name='kmu_per_cluster_2')\n",
    "#     mean_kmu = kmu_per_cluster_2[\"kmu_per_cluster_2\"].mean()\n",
    "#     print(mean_kmu)\n",
    "\n",
    "# # y = gemiddelde snelheid per cluster\n",
    "# # x = eps\n",
    "\n",
    "# # gemiddelde_kmu_per_eps(mean_kmu)\n",
    "\n",
    "# print(model)\n",
    "# # gemiddelde_kmu_per_eps(mean_kmu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
